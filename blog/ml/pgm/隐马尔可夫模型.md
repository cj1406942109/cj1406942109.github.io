# 隐马尔可夫模型
> 记录时间：2018-09-03

隐马尔可夫模型（Hidden Markov Model, HMM）是结构最简单的动态贝叶斯网络（dynamic Bayesian Network），是一种著名的有向图模型，主要用于时序数据建模，在语音识别、自然语言 处理等领域有广泛应用。

## 隐马尔可夫模型的图结构

隐马尔可夫模型中的变量分为两组。如图：

![隐马尔可夫模型的图结构](http://s1.cdn.deahu.com/show/lfile/F2B87C82F52A64EB941FEA17F26994E9.jpg)

第一组是状态变量$\lbrace y_{1}, y_{2}, ..., y_{n} \rbrace$，其中 $y_{i} \in \mathcal{Y}$  表示第$i$时刻的系统状态。通常假定状态变量是隐藏的、不可被观测的，因此状态变量也被称为隐变量。
第二组是观测变量$\lbrace x_{1}, x_{2}, ..., x_{n} \rbrace$，其中$x_{i} \in \mathcal{X}$表示第$i$时刻的观测值。

在隐马尔可夫模型中，系统通常在多个状态$\lbrace s_{1}, s_{2}, ..., s_{N} \rbrace$之间转换，因此状态变量$y_{i}$的取值范围$\mathcal{Y}$（也称为状态空间）通常是有$N$个可能取值的离散空间。

观测变量$x_{i}$可以是离散型也可以是连续型。为了便于讨论，只考虑离散型观测变量，假定其取值范围（观测空间）$\mathcal{X} = \lbrace o_{1}, o_{2}, ..., o_{N} \rbrace$。

## 马尔可夫链

马尔可夫为了简化随机过程的研究问题，提出了一种简化的假设：随机过程中，各个状态$S_{t}$的概率分布，只与它的前一个状态$S_{t-1}$有关，即
$$ P(S_{t} \vert S_{1},S_{2},...,S_{t-1}) = P(S_{t} \vert S{t-1}) $$
该假设被命名为马尔可夫假设，符合该假设的随机过程称为马尔可夫过程，也称为马尔可夫链。

上图中的箭头表示变量间的依赖关系。  
任一时刻，观测变量的取值仅依赖于状态变量，即$x_{t}$由$y_{t}$确定，与其他状态变量与观测变量的取值无关。  
同时，$t$时刻的状态$y_{t}$仅依赖于$t-1$时刻的状态$y_{t-1}$，与此前$t-2$个状态无关。

这就是所谓的马尔可夫链（Markov chain）：系统下一时刻的状态仅由当前状态决定，不依赖于以往的任何状态。如果$X_{n+1}$对于过去状态的条件概率分布仅是$X_{n}$的一个函数，则
$$P(X_{n+1} \vert X_{1} = x_{1}, X_{2} = x_{2}, ..., X_{n} = x_{n}) = P(X_{n+1} \vert X_{n} = x_{n})$$
$$ P(x_{1}, x_{2}, ..., x_{n}) = P(x_{1})P(x_{2} \vert x_{1})...P(x_{n} \vert x_{n-1}) $$

基于这种依赖关系，所有变量的联合概率分布为：
$$
P(x_{1}, y_{1}, ..., x_{n}, y_{n}) =
P(y_{1}, y_{2}, ..., y_{n})P(x_{1}, x_{2}, ..., x_{n} \vert y_{1}, y_{2}, ..., y_{n})
$$
$$
P(y_{1}, y_{2}, ..., y_{n}) = P(y_{1})\prod_{i=2}^nP(y_{i}|y_{i-1})
$$
$$
P(x_{1}, x_{2}, ..., x_{n} \vert y_{1}, y_{2}, ..., y_{n}) = \prod_{i=1}^nP(x_{i} \vert y_{i})
$$
$$
P(x_{1}, y_{1}, ..., x_{n}, y_{n}) = P(y_{1})P(x_{1} \vert y_{1})\prod_{i=2}^nP(y_{i} \vert y_{i-1})P(x_{i} \vert y_{i})
$$

## 隐马尔可夫模型的参数

想要确定一个隐马尔可夫模型，需要以下三组参数：

- 状态转移概率： 模型在各个状态之间转换的概率，通常记为矩阵$A = \lbrack a_{ij} \rbrack_{N \times N}$，其中
  $$a_{ij} = P(y_{t+1} = s_{j} \vert y_{t} = s_{i}), 1 \le i,j \le N$$
  表示在任意时刻$t$，若状态为$s_{i}$，则，在下一时刻状态为$s_{i}$的概率。
- 输出观测概率：模型根据当前状态获得各个观测值的概率，通常记为矩阵$B = \lbrack b_{ij} \rbrack_{N \times M}$，其中
  $$b_{ij} = P(x_{t+1} = o_{j} \vert y_{t} = s_{i}), 1 \le i \le N, 1 \le j \le M$$
  表示在任意时刻$t$，若状态为$s_{i}$，则观测值为$o_{j}$的概率。
- 初始状态概率：模型在初始时刻个状态出现的概率，通常记为$\pi = (\pi_{1}, \pi_{2}, ..., \pi_{N})$，其中
  $$\pi_{i} = P(y_{1} = s_{i}), 1 \le i \le N$$
  表示模型的初始状态为$s_{i}$的概率。

通过指定状态空间$\mathcal{Y}$、观测空间$\mathcal{X}$、状态转移概率概率$A$、输出观测概率$B$和初始状态概率$\pi$，就能确定一个隐马尔可夫模型。通常用其参数$\lambda = \lbrack A, B, \pi \rbrack$来指代该隐马尔可夫模型。

## 隐马尔可夫模型$\lambda$产生观测序列的过程

给定隐马尔科夫模型$\lambda$，它按如下过程产生观测序列$\lbrace x_{1}, x_{2}, ..., x_{n} \rbrace$：

1. 设置$t = 1$， 并根据初始状态概率$\pi$选择初始状态$y_{1}$；
2. 根据初始状态$y_{t}$和输出观测概率$B$选择观测变量取值$x_{t}$；
3. 根据状态$y_{t}$和状态转移概率$A$，转移模型状态，即确定$y_{t+1}$；
4. 若$t \lt n$，设置$t= t+1$，并转到第2步，否则停止。

其中$y_{t} \in \lbrace s_{1}, s_{2}, ..., s_{N} \rbrace$和$x_{t} \in \lbrace o_{1}, o_{2}, ..., o_{M} \rbrace$分别为第$t$时刻的状态和观测值。

## 实际应用中隐马尔可夫模型的三个基本问题

- 如何评估模型与观测序列之间的匹配程度？  
  即：给定模型$\lambda = \lbrack A, B, \pi \rbrack$，如何有效计算其产生的观测序列$\lbrace x = x_{1}, x_{2}, ..., x_{n} \rbrace$的概率 $P(x \vert \lambda)$？
- 如何根据观测序列推断出隐藏的模型状态？  
  即：给定模型$\lambda = \lbrack A, B, \pi \rbrack$和观测序列$\lbrace x = x_{1}, x_{2}, ..., x_{n} \rbrace$，如何找到与此观测序列最匹配的状态序列$y = \lbrace y_{1}, y_{2}, ..., y_{n}\rbrace$？
- 如何训练模型使其能最好地描述观测数据？  
  即：给定观测序列$\lbrace x = x_{1}, x_{2}, ..., x_{n} \rbrace$，如何调整模型参数$\lambda = \lbrack A, B, \pi \rbrack$使得该序列出现的概率$P(x \vert \lambda)$最大？

如：  
许多任务要根据以往的观测序列$\lbrace x_{1}, x_{2}, ..., x_{n} \rbrace$来预测当前时刻最有可能的观测值$x_{n}$，即第一个问题，求取$P(x \vert \lambda)$。

语音识别等任务中，观测值为语音信号，隐藏状态为文字，目标就是根据观测信号来推断最有可能的文字序列，即第二个问题。

在大多数现实应用中，人工指定模型参数已经变得不可行，如何根据训练样本学得最优的模型参数，就是第三个问题。
